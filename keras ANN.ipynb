{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5359 samples, validate on 2641 samples\n",
      "Epoch 1/100\n",
      "5359/5359 [==============================] - 2s 367us/step - loss: 0.8454 - accuracy: 0.5251 - val_loss: 0.5401 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "5359/5359 [==============================] - 2s 314us/step - loss: 0.5016 - accuracy: 0.7897 - val_loss: 0.4918 - val_accuracy: 0.7940\n",
      "Epoch 3/100\n",
      "5359/5359 [==============================] - 2s 301us/step - loss: 0.4663 - accuracy: 0.8003 - val_loss: 0.4661 - val_accuracy: 0.8001\n",
      "Epoch 4/100\n",
      "5359/5359 [==============================] - 1s 258us/step - loss: 0.4398 - accuracy: 0.8056 - val_loss: 0.4441 - val_accuracy: 0.8016\n",
      "Epoch 5/100\n",
      "5359/5359 [==============================] - 1s 253us/step - loss: 0.4159 - accuracy: 0.8123 - val_loss: 0.4249 - val_accuracy: 0.8141\n",
      "Epoch 6/100\n",
      "5359/5359 [==============================] - 2s 281us/step - loss: 0.3957 - accuracy: 0.8285 - val_loss: 0.4093 - val_accuracy: 0.8183\n",
      "Epoch 7/100\n",
      "5359/5359 [==============================] - 1s 252us/step - loss: 0.3828 - accuracy: 0.8364 - val_loss: 0.3994 - val_accuracy: 0.8270\n",
      "Epoch 8/100\n",
      "5359/5359 [==============================] - 1s 218us/step - loss: 0.3740 - accuracy: 0.8455 - val_loss: 0.3923 - val_accuracy: 0.8315\n",
      "Epoch 9/100\n",
      "5359/5359 [==============================] - 1s 267us/step - loss: 0.3683 - accuracy: 0.8455 - val_loss: 0.3869 - val_accuracy: 0.8364\n",
      "Epoch 10/100\n",
      "5359/5359 [==============================] - 2s 314us/step - loss: 0.3638 - accuracy: 0.8485 - val_loss: 0.3840 - val_accuracy: 0.8410\n",
      "Epoch 11/100\n",
      "5359/5359 [==============================] - 2s 345us/step - loss: 0.3608 - accuracy: 0.8492 - val_loss: 0.3810 - val_accuracy: 0.8421\n",
      "Epoch 12/100\n",
      "5359/5359 [==============================] - 2s 288us/step - loss: 0.3582 - accuracy: 0.8509 - val_loss: 0.3792 - val_accuracy: 0.8425\n",
      "Epoch 13/100\n",
      "5359/5359 [==============================] - 2s 303us/step - loss: 0.3567 - accuracy: 0.8498 - val_loss: 0.3777 - val_accuracy: 0.8429\n",
      "Epoch 14/100\n",
      "5359/5359 [==============================] - 2s 326us/step - loss: 0.3550 - accuracy: 0.8518 - val_loss: 0.3766 - val_accuracy: 0.8436\n",
      "Epoch 15/100\n",
      "5359/5359 [==============================] - 2s 376us/step - loss: 0.3538 - accuracy: 0.8530 - val_loss: 0.3761 - val_accuracy: 0.8429\n",
      "Epoch 16/100\n",
      "5359/5359 [==============================] - 2s 287us/step - loss: 0.3529 - accuracy: 0.8515 - val_loss: 0.3749 - val_accuracy: 0.8432\n",
      "Epoch 17/100\n",
      "5359/5359 [==============================] - 1s 260us/step - loss: 0.3516 - accuracy: 0.8528 - val_loss: 0.3748 - val_accuracy: 0.8432\n",
      "Epoch 18/100\n",
      "5359/5359 [==============================] - 1s 201us/step - loss: 0.3507 - accuracy: 0.8533 - val_loss: 0.3740 - val_accuracy: 0.8440\n",
      "Epoch 19/100\n",
      "5359/5359 [==============================] - 2s 294us/step - loss: 0.3496 - accuracy: 0.8559 - val_loss: 0.3737 - val_accuracy: 0.8436\n",
      "Epoch 20/100\n",
      "5359/5359 [==============================] - 1s 231us/step - loss: 0.3488 - accuracy: 0.8552 - val_loss: 0.3730 - val_accuracy: 0.8429\n",
      "Epoch 21/100\n",
      "5359/5359 [==============================] - 1s 236us/step - loss: 0.3476 - accuracy: 0.8565 - val_loss: 0.3724 - val_accuracy: 0.8444\n",
      "Epoch 22/100\n",
      "5359/5359 [==============================] - 1s 240us/step - loss: 0.3469 - accuracy: 0.8554 - val_loss: 0.3718 - val_accuracy: 0.8444\n",
      "Epoch 23/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3461 - accuracy: 0.8561 - val_loss: 0.3713 - val_accuracy: 0.8451\n",
      "Epoch 24/100\n",
      "5359/5359 [==============================] - 1s 233us/step - loss: 0.3453 - accuracy: 0.8563 - val_loss: 0.3708 - val_accuracy: 0.8470\n",
      "Epoch 25/100\n",
      "5359/5359 [==============================] - 1s 235us/step - loss: 0.3445 - accuracy: 0.8574 - val_loss: 0.3709 - val_accuracy: 0.8455\n",
      "Epoch 26/100\n",
      "5359/5359 [==============================] - 1s 233us/step - loss: 0.3441 - accuracy: 0.8571 - val_loss: 0.3703 - val_accuracy: 0.8451\n",
      "Epoch 27/100\n",
      "5359/5359 [==============================] - 1s 229us/step - loss: 0.3432 - accuracy: 0.8582 - val_loss: 0.3696 - val_accuracy: 0.8444\n",
      "Epoch 28/100\n",
      "5359/5359 [==============================] - 1s 228us/step - loss: 0.3426 - accuracy: 0.8584 - val_loss: 0.3698 - val_accuracy: 0.8451\n",
      "Epoch 29/100\n",
      "5359/5359 [==============================] - 1s 238us/step - loss: 0.3422 - accuracy: 0.8595 - val_loss: 0.3697 - val_accuracy: 0.8463\n",
      "Epoch 30/100\n",
      "5359/5359 [==============================] - 1s 221us/step - loss: 0.3414 - accuracy: 0.8580 - val_loss: 0.3695 - val_accuracy: 0.8482\n",
      "Epoch 31/100\n",
      "5359/5359 [==============================] - 1s 185us/step - loss: 0.3410 - accuracy: 0.8586 - val_loss: 0.3692 - val_accuracy: 0.8463\n",
      "Epoch 32/100\n",
      "5359/5359 [==============================] - 1s 225us/step - loss: 0.3406 - accuracy: 0.8589 - val_loss: 0.3693 - val_accuracy: 0.8459\n",
      "Epoch 33/100\n",
      "5359/5359 [==============================] - 1s 234us/step - loss: 0.3403 - accuracy: 0.8604 - val_loss: 0.3690 - val_accuracy: 0.8455\n",
      "Epoch 34/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3399 - accuracy: 0.8591 - val_loss: 0.3688 - val_accuracy: 0.8451\n",
      "Epoch 35/100\n",
      "5359/5359 [==============================] - 1s 229us/step - loss: 0.3395 - accuracy: 0.8608 - val_loss: 0.3686 - val_accuracy: 0.8466\n",
      "Epoch 36/100\n",
      "5359/5359 [==============================] - 1s 232us/step - loss: 0.3385 - accuracy: 0.8589 - val_loss: 0.3703 - val_accuracy: 0.8455\n",
      "Epoch 37/100\n",
      "5359/5359 [==============================] - 1s 231us/step - loss: 0.3391 - accuracy: 0.8586 - val_loss: 0.3681 - val_accuracy: 0.8489\n",
      "Epoch 38/100\n",
      "5359/5359 [==============================] - 1s 228us/step - loss: 0.3383 - accuracy: 0.8599 - val_loss: 0.3687 - val_accuracy: 0.8474\n",
      "Epoch 39/100\n",
      "5359/5359 [==============================] - 1s 229us/step - loss: 0.3382 - accuracy: 0.8599 - val_loss: 0.3684 - val_accuracy: 0.8459\n",
      "Epoch 40/100\n",
      "5359/5359 [==============================] - 1s 239us/step - loss: 0.3377 - accuracy: 0.8595 - val_loss: 0.3680 - val_accuracy: 0.8474\n",
      "Epoch 41/100\n",
      "5359/5359 [==============================] - 1s 229us/step - loss: 0.3379 - accuracy: 0.8595 - val_loss: 0.3681 - val_accuracy: 0.8432\n",
      "Epoch 42/100\n",
      "5359/5359 [==============================] - 1s 245us/step - loss: 0.3372 - accuracy: 0.8619 - val_loss: 0.3675 - val_accuracy: 0.8459\n",
      "Epoch 43/100\n",
      "5359/5359 [==============================] - 1s 243us/step - loss: 0.3369 - accuracy: 0.8614 - val_loss: 0.3671 - val_accuracy: 0.8474\n",
      "Epoch 44/100\n",
      "5359/5359 [==============================] - 1s 221us/step - loss: 0.3362 - accuracy: 0.8602 - val_loss: 0.3666 - val_accuracy: 0.8478\n",
      "Epoch 45/100\n",
      "5359/5359 [==============================] - 1s 233us/step - loss: 0.3362 - accuracy: 0.8627 - val_loss: 0.3662 - val_accuracy: 0.8482\n",
      "Epoch 46/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3357 - accuracy: 0.8627 - val_loss: 0.3659 - val_accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "5359/5359 [==============================] - 1s 229us/step - loss: 0.3357 - accuracy: 0.8630 - val_loss: 0.3656 - val_accuracy: 0.8482\n",
      "Epoch 48/100\n",
      "5359/5359 [==============================] - 1s 240us/step - loss: 0.3350 - accuracy: 0.8628 - val_loss: 0.3649 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "5359/5359 [==============================] - 1s 222us/step - loss: 0.3343 - accuracy: 0.8643 - val_loss: 0.3649 - val_accuracy: 0.8504\n",
      "Epoch 50/100\n",
      "5359/5359 [==============================] - 1s 229us/step - loss: 0.3343 - accuracy: 0.8643 - val_loss: 0.3640 - val_accuracy: 0.8497\n",
      "Epoch 51/100\n",
      "5359/5359 [==============================] - 1s 239us/step - loss: 0.3340 - accuracy: 0.8660 - val_loss: 0.3642 - val_accuracy: 0.8501\n",
      "Epoch 52/100\n",
      "5359/5359 [==============================] - 1s 233us/step - loss: 0.3335 - accuracy: 0.8645 - val_loss: 0.3652 - val_accuracy: 0.8497\n",
      "Epoch 53/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3333 - accuracy: 0.8666 - val_loss: 0.3647 - val_accuracy: 0.8504\n",
      "Epoch 54/100\n",
      "5359/5359 [==============================] - 1s 231us/step - loss: 0.3328 - accuracy: 0.8647 - val_loss: 0.3636 - val_accuracy: 0.8504\n",
      "Epoch 55/100\n",
      "5359/5359 [==============================] - 1s 245us/step - loss: 0.3324 - accuracy: 0.8677 - val_loss: 0.3639 - val_accuracy: 0.8516\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5359/5359 [==============================] - 1s 227us/step - loss: 0.3324 - accuracy: 0.8651 - val_loss: 0.3631 - val_accuracy: 0.8527\n",
      "Epoch 57/100\n",
      "5359/5359 [==============================] - 1s 198us/step - loss: 0.3323 - accuracy: 0.8670 - val_loss: 0.3633 - val_accuracy: 0.8527\n",
      "Epoch 58/100\n",
      "5359/5359 [==============================] - 1s 226us/step - loss: 0.3318 - accuracy: 0.8655 - val_loss: 0.3631 - val_accuracy: 0.8516\n",
      "Epoch 59/100\n",
      "5359/5359 [==============================] - 1s 223us/step - loss: 0.3316 - accuracy: 0.8647 - val_loss: 0.3626 - val_accuracy: 0.8527\n",
      "Epoch 60/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3311 - accuracy: 0.8660 - val_loss: 0.3624 - val_accuracy: 0.8523\n",
      "Epoch 61/100\n",
      "5359/5359 [==============================] - 1s 225us/step - loss: 0.3310 - accuracy: 0.8673 - val_loss: 0.3623 - val_accuracy: 0.8546\n",
      "Epoch 62/100\n",
      "5359/5359 [==============================] - 1s 240us/step - loss: 0.3308 - accuracy: 0.8662 - val_loss: 0.3627 - val_accuracy: 0.8497\n",
      "Epoch 63/100\n",
      "5359/5359 [==============================] - 1s 227us/step - loss: 0.3307 - accuracy: 0.8660 - val_loss: 0.3618 - val_accuracy: 0.8527\n",
      "Epoch 64/100\n",
      "5359/5359 [==============================] - 1s 236us/step - loss: 0.3303 - accuracy: 0.8677 - val_loss: 0.3617 - val_accuracy: 0.8512\n",
      "Epoch 65/100\n",
      "5359/5359 [==============================] - 1s 233us/step - loss: 0.3299 - accuracy: 0.8658 - val_loss: 0.3613 - val_accuracy: 0.8535\n",
      "Epoch 66/100\n",
      "5359/5359 [==============================] - 1s 227us/step - loss: 0.3298 - accuracy: 0.8666 - val_loss: 0.3613 - val_accuracy: 0.8535\n",
      "Epoch 67/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3292 - accuracy: 0.8681 - val_loss: 0.3616 - val_accuracy: 0.8535\n",
      "Epoch 68/100\n",
      "5359/5359 [==============================] - 1s 242us/step - loss: 0.3296 - accuracy: 0.8656 - val_loss: 0.3608 - val_accuracy: 0.8542\n",
      "Epoch 69/100\n",
      "5359/5359 [==============================] - 1s 214us/step - loss: 0.3287 - accuracy: 0.8666 - val_loss: 0.3614 - val_accuracy: 0.8546\n",
      "Epoch 70/100\n",
      "5359/5359 [==============================] - 1s 194us/step - loss: 0.3283 - accuracy: 0.8666 - val_loss: 0.3615 - val_accuracy: 0.8519\n",
      "Epoch 71/100\n",
      "5359/5359 [==============================] - 1s 225us/step - loss: 0.3283 - accuracy: 0.8653 - val_loss: 0.3608 - val_accuracy: 0.8546\n",
      "Epoch 72/100\n",
      "5359/5359 [==============================] - 1s 224us/step - loss: 0.3280 - accuracy: 0.8655 - val_loss: 0.3611 - val_accuracy: 0.8527\n",
      "Epoch 73/100\n",
      "5359/5359 [==============================] - 1s 223us/step - loss: 0.3278 - accuracy: 0.8677 - val_loss: 0.3608 - val_accuracy: 0.8531\n",
      "Epoch 74/100\n",
      "5359/5359 [==============================] - 1s 226us/step - loss: 0.3276 - accuracy: 0.8662 - val_loss: 0.3605 - val_accuracy: 0.8516\n",
      "Epoch 75/100\n",
      "5359/5359 [==============================] - 1s 224us/step - loss: 0.3272 - accuracy: 0.8662 - val_loss: 0.3605 - val_accuracy: 0.8531\n",
      "Epoch 76/100\n",
      "5359/5359 [==============================] - 1s 224us/step - loss: 0.3268 - accuracy: 0.8666 - val_loss: 0.3596 - val_accuracy: 0.8527\n",
      "Epoch 77/100\n",
      "5359/5359 [==============================] - 1s 226us/step - loss: 0.3267 - accuracy: 0.8668 - val_loss: 0.3604 - val_accuracy: 0.8538\n",
      "Epoch 78/100\n",
      "5359/5359 [==============================] - 1s 225us/step - loss: 0.3265 - accuracy: 0.8688 - val_loss: 0.3607 - val_accuracy: 0.8535\n",
      "Epoch 79/100\n",
      "5359/5359 [==============================] - 1s 226us/step - loss: 0.3264 - accuracy: 0.8683 - val_loss: 0.3605 - val_accuracy: 0.8516\n",
      "Epoch 80/100\n",
      "5359/5359 [==============================] - 1s 226us/step - loss: 0.3262 - accuracy: 0.8694 - val_loss: 0.3601 - val_accuracy: 0.8538\n",
      "Epoch 81/100\n",
      "5359/5359 [==============================] - 1s 237us/step - loss: 0.3258 - accuracy: 0.8670 - val_loss: 0.3607 - val_accuracy: 0.8535\n",
      "Epoch 82/100\n",
      "5359/5359 [==============================] - 1s 241us/step - loss: 0.3260 - accuracy: 0.8686 - val_loss: 0.3600 - val_accuracy: 0.8535\n",
      "Epoch 83/100\n",
      "5359/5359 [==============================] - 1s 165us/step - loss: 0.3254 - accuracy: 0.8683 - val_loss: 0.3606 - val_accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "5359/5359 [==============================] - 1s 232us/step - loss: 0.3257 - accuracy: 0.8675 - val_loss: 0.3598 - val_accuracy: 0.8531\n",
      "Epoch 85/100\n",
      "5359/5359 [==============================] - 1s 231us/step - loss: 0.3253 - accuracy: 0.8683 - val_loss: 0.3603 - val_accuracy: 0.8538\n",
      "Epoch 86/100\n",
      "5359/5359 [==============================] - 1s 228us/step - loss: 0.3252 - accuracy: 0.8673 - val_loss: 0.3602 - val_accuracy: 0.8516\n",
      "Epoch 87/100\n",
      "5359/5359 [==============================] - 1s 228us/step - loss: 0.3251 - accuracy: 0.8670 - val_loss: 0.3600 - val_accuracy: 0.8527\n",
      "Epoch 88/100\n",
      "5359/5359 [==============================] - 1s 227us/step - loss: 0.3246 - accuracy: 0.8679 - val_loss: 0.3607 - val_accuracy: 0.8516\n",
      "Epoch 89/100\n",
      "5359/5359 [==============================] - 1s 231us/step - loss: 0.3250 - accuracy: 0.8694 - val_loss: 0.3601 - val_accuracy: 0.8527\n",
      "Epoch 90/100\n",
      "5359/5359 [==============================] - 1s 228us/step - loss: 0.3248 - accuracy: 0.8679 - val_loss: 0.3599 - val_accuracy: 0.8527\n",
      "Epoch 91/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3245 - accuracy: 0.8683 - val_loss: 0.3608 - val_accuracy: 0.8519\n",
      "Epoch 92/100\n",
      "5359/5359 [==============================] - 1s 229us/step - loss: 0.3246 - accuracy: 0.8684 - val_loss: 0.3604 - val_accuracy: 0.8508\n",
      "Epoch 93/100\n",
      "5359/5359 [==============================] - 1s 230us/step - loss: 0.3246 - accuracy: 0.8698 - val_loss: 0.3599 - val_accuracy: 0.8519\n",
      "Epoch 94/100\n",
      "5359/5359 [==============================] - 1s 233us/step - loss: 0.3243 - accuracy: 0.8686 - val_loss: 0.3590 - val_accuracy: 0.8535\n",
      "Epoch 95/100\n",
      "5359/5359 [==============================] - 1s 244us/step - loss: 0.3245 - accuracy: 0.8696 - val_loss: 0.3597 - val_accuracy: 0.8523\n",
      "Epoch 96/100\n",
      "5359/5359 [==============================] - 1s 178us/step - loss: 0.3243 - accuracy: 0.8683 - val_loss: 0.3595 - val_accuracy: 0.8538\n",
      "Epoch 97/100\n",
      "5359/5359 [==============================] - 1s 222us/step - loss: 0.3243 - accuracy: 0.8683 - val_loss: 0.3589 - val_accuracy: 0.8535\n",
      "Epoch 98/100\n",
      "5359/5359 [==============================] - 1s 223us/step - loss: 0.3239 - accuracy: 0.8690 - val_loss: 0.3593 - val_accuracy: 0.8538\n",
      "Epoch 99/100\n",
      "5359/5359 [==============================] - 1s 224us/step - loss: 0.3242 - accuracy: 0.8684 - val_loss: 0.3595 - val_accuracy: 0.8531\n",
      "Epoch 100/100\n",
      "5359/5359 [==============================] - 1s 224us/step - loss: 0.3235 - accuracy: 0.8688 - val_loss: 0.3602 - val_accuracy: 0.8519\n",
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-97d0869e7d75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n",
    "\n",
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)\n",
    "\n",
    "## Concatenate the Data Frames\n",
    "\n",
    "X=pd.concat([X,geography,gender],axis=1)\n",
    "\n",
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu',input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Germany  Spain\n",
       "0        0      0\n",
       "1        0      1\n",
       "2        0      0\n",
       "3        0      0\n",
       "4        0      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geography.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Male\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the Data Frames\n",
    "\n",
    "X=pd.concat([X,geography,gender],axis=1)\n",
    "\n",
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
       "0               1        101348.88        0      0     0  \n",
       "1               1        112542.58        0      1     0  \n",
       "2               0        113931.57        0      0     0  \n",
       "3               0         93826.63        0      0     0  \n",
       "4               1         79084.10        0      1     0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"he_uniform\")`\n",
      "  \n",
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Aashna Vaid\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5359 samples, validate on 2641 samples\n",
      "Epoch 1/100\n",
      "5359/5359 [==============================] - 3s 499us/step - loss: 0.5357 - accuracy: 0.7393 - val_loss: 0.4753 - val_accuracy: 0.7910\n",
      "Epoch 2/100\n",
      "5359/5359 [==============================] - 3s 476us/step - loss: 0.4620 - accuracy: 0.7960 - val_loss: 0.4522 - val_accuracy: 0.7948\n",
      "Epoch 3/100\n",
      "5359/5359 [==============================] - 2s 335us/step - loss: 0.4447 - accuracy: 0.7977 - val_loss: 0.4379 - val_accuracy: 0.7963\n",
      "Epoch 4/100\n",
      "5359/5359 [==============================] - 2s 403us/step - loss: 0.4317 - accuracy: 0.8011 - val_loss: 0.4279 - val_accuracy: 0.8001\n",
      "Epoch 5/100\n",
      "5359/5359 [==============================] - 3s 495us/step - loss: 0.4222 - accuracy: 0.8093 - val_loss: 0.4210 - val_accuracy: 0.8152\n",
      "Epoch 6/100\n",
      "5359/5359 [==============================] - 2s 391us/step - loss: 0.4147 - accuracy: 0.8203 - val_loss: 0.4147 - val_accuracy: 0.8201\n",
      "Epoch 7/100\n",
      "5359/5359 [==============================] - 2s 370us/step - loss: 0.4076 - accuracy: 0.8252 - val_loss: 0.4094 - val_accuracy: 0.8201\n",
      "Epoch 8/100\n",
      "5359/5359 [==============================] - 2s 351us/step - loss: 0.4013 - accuracy: 0.8280 - val_loss: 0.4052 - val_accuracy: 0.8243\n",
      "Epoch 9/100\n",
      "5359/5359 [==============================] - 2s 463us/step - loss: 0.3957 - accuracy: 0.8313 - val_loss: 0.4023 - val_accuracy: 0.8254\n",
      "Epoch 10/100\n",
      "5359/5359 [==============================] - 2s 399us/step - loss: 0.3915 - accuracy: 0.8321 - val_loss: 0.3993 - val_accuracy: 0.8262\n",
      "Epoch 11/100\n",
      "5359/5359 [==============================] - 2s 385us/step - loss: 0.3875 - accuracy: 0.8347 - val_loss: 0.3966 - val_accuracy: 0.8270\n",
      "Epoch 12/100\n",
      "5359/5359 [==============================] - 2s 394us/step - loss: 0.3838 - accuracy: 0.8362 - val_loss: 0.3940 - val_accuracy: 0.8289\n",
      "Epoch 13/100\n",
      "5359/5359 [==============================] - 2s 368us/step - loss: 0.3806 - accuracy: 0.8367 - val_loss: 0.3921 - val_accuracy: 0.8304\n",
      "Epoch 14/100\n",
      "5359/5359 [==============================] - 2s 433us/step - loss: 0.3772 - accuracy: 0.8399 - val_loss: 0.3901 - val_accuracy: 0.8323\n",
      "Epoch 15/100\n",
      "5359/5359 [==============================] - 2s 410us/step - loss: 0.3741 - accuracy: 0.8401 - val_loss: 0.3884 - val_accuracy: 0.8296\n",
      "Epoch 16/100\n",
      "5359/5359 [==============================] - 2s 412us/step - loss: 0.3715 - accuracy: 0.8425 - val_loss: 0.3868 - val_accuracy: 0.8323\n",
      "Epoch 17/100\n",
      "5359/5359 [==============================] - 2s 373us/step - loss: 0.3687 - accuracy: 0.8438 - val_loss: 0.3858 - val_accuracy: 0.8330\n",
      "Epoch 18/100\n",
      "5359/5359 [==============================] - 2s 353us/step - loss: 0.3660 - accuracy: 0.8470 - val_loss: 0.3859 - val_accuracy: 0.8323\n",
      "Epoch 19/100\n",
      "5359/5359 [==============================] - 2s 365us/step - loss: 0.3642 - accuracy: 0.8489 - val_loss: 0.3829 - val_accuracy: 0.8338\n",
      "Epoch 20/100\n",
      "5359/5359 [==============================] - 2s 459us/step - loss: 0.3620 - accuracy: 0.8502 - val_loss: 0.3813 - val_accuracy: 0.8345\n",
      "Epoch 21/100\n",
      "5359/5359 [==============================] - 2s 447us/step - loss: 0.3599 - accuracy: 0.8513 - val_loss: 0.3799 - val_accuracy: 0.8364\n",
      "Epoch 22/100\n",
      "5359/5359 [==============================] - 2s 387us/step - loss: 0.3580 - accuracy: 0.8505 - val_loss: 0.3784 - val_accuracy: 0.8379\n",
      "Epoch 23/100\n",
      "5359/5359 [==============================] - 2s 353us/step - loss: 0.3559 - accuracy: 0.8522 - val_loss: 0.3771 - val_accuracy: 0.8391\n",
      "Epoch 24/100\n",
      "5359/5359 [==============================] - 2s 376us/step - loss: 0.3539 - accuracy: 0.8545 - val_loss: 0.3759 - val_accuracy: 0.8402\n",
      "Epoch 25/100\n",
      "5359/5359 [==============================] - 2s 382us/step - loss: 0.3525 - accuracy: 0.8541 - val_loss: 0.3747 - val_accuracy: 0.8413\n",
      "Epoch 26/100\n",
      "5359/5359 [==============================] - 2s 380us/step - loss: 0.3508 - accuracy: 0.8545 - val_loss: 0.3740 - val_accuracy: 0.8429\n",
      "Epoch 27/100\n",
      "5359/5359 [==============================] - 2s 398us/step - loss: 0.3492 - accuracy: 0.8574 - val_loss: 0.3724 - val_accuracy: 0.8417\n",
      "Epoch 28/100\n",
      "5359/5359 [==============================] - 2s 466us/step - loss: 0.3476 - accuracy: 0.8563 - val_loss: 0.3727 - val_accuracy: 0.8406\n",
      "Epoch 29/100\n",
      "5359/5359 [==============================] - 2s 441us/step - loss: 0.3468 - accuracy: 0.8578 - val_loss: 0.3709 - val_accuracy: 0.8436\n",
      "Epoch 30/100\n",
      "5359/5359 [==============================] - 2s 349us/step - loss: 0.3461 - accuracy: 0.8580 - val_loss: 0.3702 - val_accuracy: 0.8425\n",
      "Epoch 31/100\n",
      "5359/5359 [==============================] - 2s 347us/step - loss: 0.3446 - accuracy: 0.8576 - val_loss: 0.3698 - val_accuracy: 0.8451\n",
      "Epoch 32/100\n",
      "5359/5359 [==============================] - 2s 406us/step - loss: 0.3439 - accuracy: 0.8582 - val_loss: 0.3680 - val_accuracy: 0.8440\n",
      "Epoch 33/100\n",
      "5359/5359 [==============================] - 2s 362us/step - loss: 0.3431 - accuracy: 0.8580 - val_loss: 0.3671 - val_accuracy: 0.8451\n",
      "Epoch 34/100\n",
      "5359/5359 [==============================] - 2s 356us/step - loss: 0.3416 - accuracy: 0.8597 - val_loss: 0.3670 - val_accuracy: 0.8440\n",
      "Epoch 35/100\n",
      "5359/5359 [==============================] - 2s 335us/step - loss: 0.3410 - accuracy: 0.8610 - val_loss: 0.3662 - val_accuracy: 0.8470\n",
      "Epoch 36/100\n",
      "5359/5359 [==============================] - 2s 344us/step - loss: 0.3399 - accuracy: 0.8593 - val_loss: 0.3656 - val_accuracy: 0.8448\n",
      "Epoch 37/100\n",
      "5359/5359 [==============================] - 2s 431us/step - loss: 0.3389 - accuracy: 0.8610 - val_loss: 0.3646 - val_accuracy: 0.8482\n",
      "Epoch 38/100\n",
      "5359/5359 [==============================] - 2s 354us/step - loss: 0.3384 - accuracy: 0.8621 - val_loss: 0.3641 - val_accuracy: 0.8485\n",
      "Epoch 39/100\n",
      "5359/5359 [==============================] - 2s 371us/step - loss: 0.3378 - accuracy: 0.8621 - val_loss: 0.3634 - val_accuracy: 0.8512\n",
      "Epoch 40/100\n",
      "5359/5359 [==============================] - 2s 401us/step - loss: 0.3373 - accuracy: 0.8615 - val_loss: 0.3626 - val_accuracy: 0.8497\n",
      "Epoch 41/100\n",
      "5359/5359 [==============================] - 2s 421us/step - loss: 0.3367 - accuracy: 0.8612 - val_loss: 0.3622 - val_accuracy: 0.8535\n",
      "Epoch 42/100\n",
      "5359/5359 [==============================] - 2s 364us/step - loss: 0.3361 - accuracy: 0.8621 - val_loss: 0.3616 - val_accuracy: 0.8485\n",
      "Epoch 43/100\n",
      "5359/5359 [==============================] - 2s 394us/step - loss: 0.3356 - accuracy: 0.8615 - val_loss: 0.3613 - val_accuracy: 0.8493\n",
      "Epoch 44/100\n",
      "5359/5359 [==============================] - 2s 378us/step - loss: 0.3356 - accuracy: 0.8610 - val_loss: 0.3621 - val_accuracy: 0.8523\n",
      "Epoch 45/100\n",
      "5359/5359 [==============================] - 2s 348us/step - loss: 0.3349 - accuracy: 0.8619 - val_loss: 0.3619 - val_accuracy: 0.8482\n",
      "Epoch 46/100\n",
      "5359/5359 [==============================] - 2s 347us/step - loss: 0.3349 - accuracy: 0.8599 - val_loss: 0.3605 - val_accuracy: 0.8535\n",
      "Epoch 47/100\n",
      "5359/5359 [==============================] - 3s 471us/step - loss: 0.3343 - accuracy: 0.8623 - val_loss: 0.3610 - val_accuracy: 0.8497\n",
      "Epoch 48/100\n",
      "5359/5359 [==============================] - 2s 407us/step - loss: 0.3345 - accuracy: 0.8615 - val_loss: 0.3602 - val_accuracy: 0.8527\n",
      "Epoch 49/100\n",
      "5359/5359 [==============================] - 2s 402us/step - loss: 0.3340 - accuracy: 0.8621 - val_loss: 0.3600 - val_accuracy: 0.8512\n",
      "Epoch 50/100\n",
      "5359/5359 [==============================] - 2s 325us/step - loss: 0.3340 - accuracy: 0.8625 - val_loss: 0.3607 - val_accuracy: 0.8523\n",
      "Epoch 51/100\n",
      "5359/5359 [==============================] - 2s 445us/step - loss: 0.3336 - accuracy: 0.8630 - val_loss: 0.3608 - val_accuracy: 0.8538\n",
      "Epoch 52/100\n",
      "5359/5359 [==============================] - 2s 335us/step - loss: 0.3337 - accuracy: 0.8634 - val_loss: 0.3597 - val_accuracy: 0.8493\n",
      "Epoch 53/100\n",
      "5359/5359 [==============================] - 2s 347us/step - loss: 0.3333 - accuracy: 0.8619 - val_loss: 0.3618 - val_accuracy: 0.8493\n",
      "Epoch 54/100\n",
      "5359/5359 [==============================] - 2s 337us/step - loss: 0.3339 - accuracy: 0.8642 - val_loss: 0.3599 - val_accuracy: 0.8501\n",
      "Epoch 55/100\n",
      "5359/5359 [==============================] - 2s 402us/step - loss: 0.3334 - accuracy: 0.8643 - val_loss: 0.3598 - val_accuracy: 0.8485\n",
      "Epoch 56/100\n",
      "5359/5359 [==============================] - 2s 340us/step - loss: 0.3332 - accuracy: 0.8632 - val_loss: 0.3592 - val_accuracy: 0.8501\n",
      "Epoch 57/100\n",
      "5359/5359 [==============================] - 2s 436us/step - loss: 0.3333 - accuracy: 0.8625 - val_loss: 0.3597 - val_accuracy: 0.8516\n",
      "Epoch 58/100\n",
      "5359/5359 [==============================] - 3s 472us/step - loss: 0.3329 - accuracy: 0.8640 - val_loss: 0.3595 - val_accuracy: 0.8508\n",
      "Epoch 59/100\n",
      "5359/5359 [==============================] - 3s 475us/step - loss: 0.3327 - accuracy: 0.8632 - val_loss: 0.3600 - val_accuracy: 0.8493\n",
      "Epoch 60/100\n",
      "5359/5359 [==============================] - 2s 327us/step - loss: 0.3328 - accuracy: 0.8645 - val_loss: 0.3586 - val_accuracy: 0.8512\n",
      "Epoch 61/100\n",
      "5359/5359 [==============================] - 2s 373us/step - loss: 0.3329 - accuracy: 0.8643 - val_loss: 0.3583 - val_accuracy: 0.8527\n",
      "Epoch 62/100\n",
      "5359/5359 [==============================] - 2s 435us/step - loss: 0.3326 - accuracy: 0.8630 - val_loss: 0.3583 - val_accuracy: 0.8516\n",
      "Epoch 63/100\n",
      "5359/5359 [==============================] - 3s 528us/step - loss: 0.3325 - accuracy: 0.8643 - val_loss: 0.3580 - val_accuracy: 0.8508\n",
      "Epoch 64/100\n",
      "5359/5359 [==============================] - 2s 394us/step - loss: 0.3326 - accuracy: 0.8630 - val_loss: 0.3582 - val_accuracy: 0.8489\n",
      "Epoch 65/100\n",
      "5359/5359 [==============================] - 2s 381us/step - loss: 0.3321 - accuracy: 0.8651 - val_loss: 0.3595 - val_accuracy: 0.8565\n",
      "Epoch 66/100\n",
      "5359/5359 [==============================] - 2s 418us/step - loss: 0.3323 - accuracy: 0.8636 - val_loss: 0.3583 - val_accuracy: 0.8504\n",
      "Epoch 67/100\n",
      "5359/5359 [==============================] - 2s 424us/step - loss: 0.3322 - accuracy: 0.8647 - val_loss: 0.3585 - val_accuracy: 0.8516\n",
      "Epoch 68/100\n",
      "5359/5359 [==============================] - 2s 361us/step - loss: 0.3320 - accuracy: 0.8653 - val_loss: 0.3574 - val_accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "5359/5359 [==============================] - 2s 335us/step - loss: 0.3319 - accuracy: 0.8634 - val_loss: 0.3581 - val_accuracy: 0.8542\n",
      "Epoch 70/100\n",
      "5359/5359 [==============================] - 2s 345us/step - loss: 0.3317 - accuracy: 0.8642 - val_loss: 0.3572 - val_accuracy: 0.8557\n",
      "Epoch 71/100\n",
      "5359/5359 [==============================] - 2s 419us/step - loss: 0.3316 - accuracy: 0.8640 - val_loss: 0.3574 - val_accuracy: 0.8550\n",
      "Epoch 72/100\n",
      "5359/5359 [==============================] - 2s 377us/step - loss: 0.3316 - accuracy: 0.8640 - val_loss: 0.3579 - val_accuracy: 0.8535\n",
      "Epoch 73/100\n",
      "5359/5359 [==============================] - 2s 407us/step - loss: 0.3313 - accuracy: 0.8632 - val_loss: 0.3574 - val_accuracy: 0.8531\n",
      "Epoch 74/100\n",
      "5359/5359 [==============================] - 2s 401us/step - loss: 0.3311 - accuracy: 0.8623 - val_loss: 0.3580 - val_accuracy: 0.8504\n",
      "Epoch 75/100\n",
      "5359/5359 [==============================] - 2s 364us/step - loss: 0.3308 - accuracy: 0.8638 - val_loss: 0.3574 - val_accuracy: 0.8542\n",
      "Epoch 76/100\n",
      "5359/5359 [==============================] - 2s 354us/step - loss: 0.3308 - accuracy: 0.8636 - val_loss: 0.3570 - val_accuracy: 0.8531\n",
      "Epoch 77/100\n",
      "5359/5359 [==============================] - 2s 354us/step - loss: 0.3312 - accuracy: 0.8636 - val_loss: 0.3566 - val_accuracy: 0.8531\n",
      "Epoch 78/100\n",
      "5359/5359 [==============================] - 2s 390us/step - loss: 0.3307 - accuracy: 0.8630 - val_loss: 0.3570 - val_accuracy: 0.8573\n",
      "Epoch 79/100\n",
      "5359/5359 [==============================] - 2s 400us/step - loss: 0.3303 - accuracy: 0.8653 - val_loss: 0.3574 - val_accuracy: 0.8546\n",
      "Epoch 80/100\n",
      "5359/5359 [==============================] - 2s 373us/step - loss: 0.3306 - accuracy: 0.8632 - val_loss: 0.3563 - val_accuracy: 0.8546\n",
      "Epoch 81/100\n",
      "5359/5359 [==============================] - 2s 386us/step - loss: 0.3305 - accuracy: 0.8640 - val_loss: 0.3566 - val_accuracy: 0.8565\n",
      "Epoch 82/100\n",
      "5359/5359 [==============================] - 2s 401us/step - loss: 0.3304 - accuracy: 0.8634 - val_loss: 0.3572 - val_accuracy: 0.8538\n",
      "Epoch 83/100\n",
      "5359/5359 [==============================] - 2s 426us/step - loss: 0.3296 - accuracy: 0.8660 - val_loss: 0.3579 - val_accuracy: 0.8554\n",
      "Epoch 84/100\n",
      "5359/5359 [==============================] - 2s 366us/step - loss: 0.3303 - accuracy: 0.8643 - val_loss: 0.3566 - val_accuracy: 0.8538\n",
      "Epoch 85/100\n",
      "5359/5359 [==============================] - 2s 363us/step - loss: 0.3300 - accuracy: 0.8658 - val_loss: 0.3565 - val_accuracy: 0.8554\n",
      "Epoch 86/100\n",
      "5359/5359 [==============================] - 2s 420us/step - loss: 0.3299 - accuracy: 0.8647 - val_loss: 0.3562 - val_accuracy: 0.8546\n",
      "Epoch 87/100\n",
      "5359/5359 [==============================] - 2s 435us/step - loss: 0.3300 - accuracy: 0.8647 - val_loss: 0.3568 - val_accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "5359/5359 [==============================] - 3s 490us/step - loss: 0.3298 - accuracy: 0.8638 - val_loss: 0.3566 - val_accuracy: 0.8565\n",
      "Epoch 89/100\n",
      "5359/5359 [==============================] - 2s 417us/step - loss: 0.3294 - accuracy: 0.8645 - val_loss: 0.3572 - val_accuracy: 0.8523\n",
      "Epoch 90/100\n",
      "5359/5359 [==============================] - 2s 346us/step - loss: 0.3297 - accuracy: 0.8656 - val_loss: 0.3561 - val_accuracy: 0.8554\n",
      "Epoch 91/100\n",
      "5359/5359 [==============================] - 2s 370us/step - loss: 0.3293 - accuracy: 0.8642 - val_loss: 0.3562 - val_accuracy: 0.8523\n",
      "Epoch 92/100\n",
      "5359/5359 [==============================] - 2s 353us/step - loss: 0.3295 - accuracy: 0.8647 - val_loss: 0.3575 - val_accuracy: 0.8531\n",
      "Epoch 93/100\n",
      "5359/5359 [==============================] - 2s 450us/step - loss: 0.3294 - accuracy: 0.8638 - val_loss: 0.3560 - val_accuracy: 0.8538\n",
      "Epoch 94/100\n",
      "5359/5359 [==============================] - 3s 569us/step - loss: 0.3294 - accuracy: 0.8634 - val_loss: 0.3560 - val_accuracy: 0.8542\n",
      "Epoch 95/100\n",
      "5359/5359 [==============================] - 3s 520us/step - loss: 0.3291 - accuracy: 0.8653 - val_loss: 0.3554 - val_accuracy: 0.8580\n",
      "Epoch 96/100\n",
      "5359/5359 [==============================] - 2s 427us/step - loss: 0.3288 - accuracy: 0.8638 - val_loss: 0.3561 - val_accuracy: 0.8565\n",
      "Epoch 97/100\n",
      "5359/5359 [==============================] - 2s 373us/step - loss: 0.3289 - accuracy: 0.8653 - val_loss: 0.3567 - val_accuracy: 0.8569\n",
      "Epoch 98/100\n",
      "5359/5359 [==============================] - 2s 348us/step - loss: 0.3288 - accuracy: 0.8656 - val_loss: 0.3559 - val_accuracy: 0.8554\n",
      "Epoch 99/100\n",
      "5359/5359 [==============================] - 2s 341us/step - loss: 0.3285 - accuracy: 0.8660 - val_loss: 0.3556 - val_accuracy: 0.8554\n",
      "Epoch 100/100\n",
      "5359/5359 [==============================] - 2s 353us/step - loss: 0.3286 - accuracy: 0.8647 - val_loss: 0.3557 - val_accuracy: 0.8557\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu',input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f27d2fe01788>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1528,   67],\n",
       "       [ 207,  198]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
